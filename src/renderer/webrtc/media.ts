import { storeToRefs } from 'pinia'
import type { Client } from './client'
import { playSound } from '@/utils'
import { useWebrtcStore } from '@/store'

const webrtcStore = useWebrtcStore()
const {
  useVideo,
  useAudio,
  useScreen,
  screenId,
  videoInputDeviceId,
  audioInputDeviceId,
  audioOutputDeviceId,
  videoInputDevices,
  audioInputDevices,
  audioOutputDevices,
  remoteVideo,
  remoteAudio,
} = storeToRefs(webrtcStore)

/**
 * Â™í‰Ωì
 */
export class MediaServer {
  client: Client | undefined
  // videoFps = reactive([5, 15, 30, 60]) // ÊØèÁßíÂ∏ßÊï∞
  declare videoElement: HTMLVideoElement
  declare audioElement: HTMLAudioElement
  declare volumeElement: HTMLDivElement | undefined

  declare localVideoStream: MediaStream
  declare localAudioStream: MediaStream

  declare remoteAvatarImage: HTMLImageElement
  declare remoteVideoElement: HTMLVideoElement
  declare remoteAudioElement: HTMLAudioElement

  constructor(client?: Client) {
    this.client = client
  }

  init(videoElement: HTMLVideoElement, audioElement: HTMLAudioElement, volumeElement?: HTMLDivElement) {
    this.videoElement = videoElement
    this.audioElement = audioElement
    this.volumeElement = volumeElement
    remoteVideo.value = []
    remoteAudio.value = []
    return this
  }

  async start() {
    const { localVideoStream, localAudioStream } = this
    if (!localVideoStream || !localAudioStream) {
      await this.initEnumerateDevices()
      await this.setupLocalVideo()
      await this.setupLocalAudio()
      if (!toValue(useVideo) || (!toValue(useVideo) && !toValue(useAudio))) {
        await this.loadLocalMedia(new MediaStream(), 'video')
      }
    }
  }

  async initEnumerateDevices() {
    console.log('05. Ëé∑ÂèñËßÜÈ¢ëÂíåÈü≥È¢ëËÆæÂ§á')
    const devices = await window.navigator.mediaDevices.enumerateDevices()

    videoInputDevices.value = devices.filter(i => i.kind === 'videoinput')
    audioInputDevices.value = devices.filter(i => i.kind === 'audioinput')
    audioOutputDevices.value = devices.filter(i => i.kind === 'audiooutput')

    videoInputDeviceId.value = videoInputDevices.value[0].deviceId
    audioInputDeviceId.value = audioInputDevices.value[0].deviceId
    audioOutputDeviceId.value = audioOutputDevices.value[0].deviceId
  }

  async setupLocalVideo(constraints?: KeyValue) {
    if (!toValue(useVideo) && !toValue(useScreen)) {
      return
    }

    console.log('üìπ ËØ∑Ê±ÇËÆøÈóÆËßÜÈ¢ëËæìÂÖ•ËÆæÂ§á')

    const videoConstraints = toValue(useVideo) || toValue(useScreen)
      ? constraints || this.getVideoConstraints('default')
      : false

    /**
     * Êõ¥Êñ∞Êú¨Âú∞Â™í‰ΩìÊµÅ
     * @param {MediaStream} stream
     */
    const updateLocalVideoMediaStream = async (stream: MediaStream) => {
      if (stream) {
        this.localVideoStream = stream
        await this.loadLocalMedia(stream, 'video')
        console.log('9. üìπ Êéà‰∫àÂØπËßÜÈ¢ëËÆæÂ§áÁöÑËÆøÈóÆÊùÉÈôê')
      }
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: videoConstraints })
      await updateLocalVideoMediaStream(stream)
    } catch (err) {
      console.error('ËÆøÈóÆËßÜÈ¢ëËÆæÂ§áÊó∂Âá∫Èîô', err)
      console.warn('ÂõûÈÄÄÂà∞ÈªòËÆ§Á∫¶Êùü')
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true })
        await updateLocalVideoMediaStream(stream)
      } catch (fallbackErr) {
        console.error('ËÆøÈóÆÂÖ∑ÊúâÈªòËÆ§Á∫¶ÊùüÁöÑËßÜÈ¢ëËÆæÂ§áÊó∂Âá∫Èîô', fallbackErr)
        playSound('alert')
      }
    }
  }

  async setupLocalAudio(constraints?: KeyValue) {
    if (!toValue(useAudio)) {
      return
    }

    console.log('üé§ ËØ∑Ê±ÇËÆøÈóÆÈü≥È¢ëËæìÂÖ•ËÆæÂ§á')

    const audioConstraints = toValue(useAudio) ? constraints || this.getAudioConstraints() : false

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: audioConstraints })
      if (stream) {
        await this.loadLocalMedia(stream, 'audio')
        if (toValue(useAudio)) {
          this.localAudioStream = stream
          // È∫¶ÂÖãÈ£éÈü≥ÈáèÊµãËØï
          // await getMicrophoneVolumeIndicator(stream)
          console.log('10. üé§ Êéà‰∫àÂØπÈü≥È¢ëËÆæÂ§áÁöÑËÆøÈóÆÊùÉÈôê')
        }
      }
    } catch (err) {
      console.log('audio', err)
      playSound('alert')
    }
  }

  async loadLocalMedia(stream: MediaStream, kind: string) {
    if (stream) {
      console.log('Âä†ËΩΩÊú¨Âú∞Â™í‰ΩìÊµÅËΩ®ÈÅì', stream.getTracks())
    }

    if (kind === 'video') {
      console.log('ËÆæÁΩÆÊú¨Âú∞ËßÜÈ¢ëÊµÅ')
      this.logStreamInfo('localVideoMediaStream', stream)
      this.attachMediaStream(this.videoElement, stream)
    } else if (kind === 'audio') {
      console.log('ËÆæÁΩÆÊú¨Âú∞Èü≥È¢ëÊµÅ')
      this.logStreamInfo('localAudioMediaStream', stream)
      this.attachMediaStream(this.audioElement, stream)
    }
  }

  /**
   * Âä†ËΩΩËøúÁ®ãÂ™í‰ΩìÊµÅ
   * @param {MediaStream} stream audio ÔΩú videoÂ™í‰ΩìÊµÅ
   * @param {object} peers Âêå‰∏ÄÊàøÈó¥ÊâÄÊúâ RTCPeer ‰ø°ÊÅØ
   * @param {string} userId socket.id
   */
  async loadRemoteMediaStream(stream: MediaStream, peers: KeyValue, userId: string, kind: string) {
    const room = peers[userId]
    console.log('REMOTE PEER INFO', room)

    if (stream) {
      console.log(`LOAD REMOTE MEDIA STREAM TRACKS - roomName:[${room.roomName}]`, stream.getTracks())
    }

    if (kind === 'video') {
      console.log('üìπ SETUP REMOTE VIDEO STREAM', stream.id)
      remoteVideo.value.push({ userId, stream, room, kind })
    } else if (kind === 'audio') {
      console.log('üîà SETUP REMOTE AUDIO STREAM', stream.id)
      remoteAudio.value.push({ userId, stream, room, kind })
    }
  }

  cleanRemoteMedia() {
    remoteVideo.value = []
    remoteAudio.value = []
  }

  // ÁõëÂê¨
  listen() {
    // Â±èÂπïÂÖ±‰∫´„ÄÅËÆæÂ§áÂàáÊç¢ - ÈúÄÈáçÊñ∞ÂàõÂª∫ stream
    watch([useScreen, videoInputDeviceId, audioInputDeviceId], async () => {
      if (useScreen.value && screenId.value) {
        // ÂàáÊç¢Âà∞Â±èÂπïÂÖ±‰∫´
        await this.setupLocalVideo({
          mandatory: {
            chromeMediaSource: 'desktop',
            chromeMediaSourceId: screenId.value,
          },
        })
      } else {
        // ÂàáÊç¢Âà∞ËßÜÈ¢ëËæìÂÖ•ËÆæÂ§á
        await this.setupLocalVideo({
          deviceId: videoInputDeviceId.value,
          ...this.getVideoConstraints('default'),
        })
      }
      // ÂàáÊç¢Âà∞Èü≥È¢ëËæìÂÖ•ËÆæÂ§á
      await this.setupLocalAudio({
        deviceId: audioInputDeviceId.value,
        ...this.getAudioConstraints(),
      })
    }, { immediate: true })

    // ÁõëÂê¨ Èü≥È¢ëËßÜÈ¢ë ÂêØÁî®/Á¶ÅÁî® - ‰∏çÈúÄÈáçÊñ∞ÂàõÂª∫ stream
    watch([useVideo, useAudio], () => {
      this.setVideoTracks(useVideo.value)
      this.setAudioTracks(useAudio.value)
    })
  }

  logStreamInfo(name: string, stream: MediaStream) {
    if ((toValue(useVideo) || toValue(useScreen)) && this.hasVideoTrack(stream)) {
      console.log(name, {
        video: {
          label: stream.getVideoTracks()[0].label,
          settings: stream.getVideoTracks()[0].getSettings(),
        },
      })
    }
    if (toValue(useAudio) && this.hasAudioTrack(stream)) {
      console.log(name, {
        audio: {
          label: stream.getAudioTracks()[0].label,
          settings: stream.getAudioTracks()[0].getSettings(),
        },
      })
    }
  }

  attachMediaStream(element: HTMLVideoElement | HTMLAudioElement, stream: MediaStream) {
    if (!element || !stream) {
      return
    }
    element.srcObject = stream
    console.log('ÊàêÂäüÂä†ËΩΩÂ™í‰ΩìÊµÅ', stream.getTracks())
  }

  // ËÆæÂ§áÊú¨Âú∞ËßÜÈ¢ëÂºÄ/ÂÖ≥
  setVideoTracks(enabled: boolean) {
    if (this.localVideoStream) {
      this.localVideoStream.getTracks().forEach((track) => {
        track.enabled = enabled
      })
    }
  }

  // ËÆæÂ§áÊú¨Âú∞Èü≥È¢ëÂºÄ/ÂÖ≥
  setAudioTracks(enabled: boolean) {
    if (this.localAudioStream) {
      this.localAudioStream.getTracks().forEach((track) => {
        track.enabled = enabled
      })
    }
  }

  /**
   * onTrack ËΩ®ÈÅìÊ∑ªÂä†Âà∞ P2P ËøûÊé•‰∫ã‰ª∂
   * https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/ontrack
   * @param {string} userId socket.id
   * @param {KeyValue} peers Âêå‰∏ÄÊàøÈó¥ÊâÄÊúâ RTCPeer ‰ø°ÊÅØ
   */
  async handleOnTrack(userId: string, peers: KeyValue) {
    if (this.client) {
      console.log('[ON TRACK] - userId', { userId })

      this.client.peerConnections[userId].ontrack = (event) => {
        const { remoteVideoElement, remoteAudioElement } = this
        // remoteAvatarImage

        const peerInfo = peers[userId]
        const { roomName } = peerInfo
        const { kind } = event.track

        console.log('[ON TRACK] - info', { userId, roomName, kind })

        if (event.streams && event.streams[0]) {
          console.log('[ON TRACK] - peers', peers)

          switch (kind) {
            case 'video':
              remoteVideoElement
                ? this.attachMediaStream(remoteVideoElement, event.streams[0])
                : this.loadRemoteMediaStream(event.streams[0], peers, userId, kind)
              break
            case 'audio':
              remoteAudioElement
                ? this.attachMediaStream(remoteAudioElement, event.streams[0])
                : this.loadRemoteMediaStream(event.streams[0], peers, userId, kind)
              break
            default:
              break
          }
        } else {
          console.log('[ON TRACK] - SCREEN SHARING', { userId, roomName, kind })
          const inboundStream = new MediaStream([event.track])
          this.attachMediaStream(remoteVideoElement, inboundStream)
        }
      }
    }
  }

  /**
   * Â∞ÜÊú¨Âú∞Èü≥ËßÜÈ¢ëÊµÅÊ∑ªÂä†Âà∞P2PËøûÊé•‰∏≠
   * https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/addTrack
   * @param {string} userId socket.id
   */
  async handleAddTracks(userId: string) {
    if (this.client) {
      const roomName = this.client.allPeers[userId].roomName
      const { localVideoStream, localAudioStream } = this
      const videoTrack = localVideoStream && localVideoStream.getVideoTracks()[0]
      const audioTrack = localAudioStream && localAudioStream.getAudioTracks()[0]

      console.log('handleAddTracks', { videoTrack, audioTrack })

      if (videoTrack) {
        console.log(`[ADD VIDEO TRACK] to Peer Name [${roomName}]`)
        this.client.peerConnections[userId].addTrack(videoTrack, localVideoStream)
      }

      if (audioTrack) {
        console.log(`[ADD AUDIO TRACK] to Peer Name [${roomName}]`)
        this.client.peerConnections[userId].addTrack(audioTrack, localAudioStream)
      }
    }
  }

  hasAudioTrack(mediaStream: MediaStream) {
    if (!mediaStream) {
      return false
    }
    const audioTracks = mediaStream.getAudioTracks()
    return audioTracks.length > 0
  }

  hasVideoTrack(mediaStream: MediaStream) {
    if (!mediaStream) {
      return false
    }
    const videoTracks = mediaStream.getVideoTracks()
    return videoTracks.length > 0
  }

  getVideoConstraints(
    quality:
      | 'default'
      | 'qvgaVideo'
      | 'vgaVideo'
      | 'hdVideo'
      | 'fhdVideo'
      | '2kVideo'
      | '4kVideo' = 'default',
    frameRate: FrameRate = { ideal: 30 },
    forceFps: boolean = false,
  ) {
    let constraints = {}

    switch (quality) {
      case 'default':
        if (forceFps) {
          constraints = {
            width: { ideal: 3840 },
            height: { ideal: 2160 },
            frameRate: { ideal: 60 },
          }
        } else {
          constraints = {
            width: { ideal: 1280 },
            height: { ideal: 720 },
            frameRate: { ideal: 30 },
          }
        }
        break
      case 'qvgaVideo':
        constraints = {
          width: { exact: 320 },
          height: { exact: 240 },
          frameRate,
        }
        break
      case 'vgaVideo':
        constraints = {
          width: { exact: 640 },
          height: { exact: 480 },
          frameRate,
        }
        break
      case 'hdVideo':
        constraints = {
          width: { exact: 1280 },
          height: { exact: 720 },
          frameRate,
        }
        break
      case 'fhdVideo':
        constraints = {
          width: { exact: 1920 },
          height: { exact: 1080 },
          frameRate,
        }
        break
      case '2kVideo':
        constraints = {
          width: { exact: 2560 },
          height: { exact: 1440 },
          frameRate,
        }
        break
      case '4kVideo':
        constraints = {
          width: { exact: 3840 },
          height: { exact: 2160 },
          frameRate,
        }
        break
      default:
        break
    }
    console.log('Video constraints', constraints)
    return constraints
  }

  getAudioConstraints() {
    const constraints = {
      autoGainControl: true, // Ëá™Âä®Â¢ûÁõä
      echoCancellation: true, // Ê∂àÈô§ÂõûÂ£∞
      noiseSuppression: true, // Âô™Â£∞ÊäëÂà∂
      sampleRate: 48000, // ÈááÊ†∑Áéá 48000 | 44100
      sampleSize: 32, // ÈááÊ†∑Â§ßÂ∞è 16 ÔΩú 32
      channelCount: 2, // ÈÄöÈÅìÊï∞ 1(mono = ÂçïÂ£∞ÈÅì) ÔΩú 2(stereo = Á´ã‰ΩìÂ£∞)
      latency: 50, // Âª∂Ëøüms min="10" max="1000" value="50" step="10"
      volume: 100 / 100, // Èü≥Èáè min="0" max="100" value="100" step="10"
    }
    console.log('Audio constraints', constraints)
    return constraints
  }
}
